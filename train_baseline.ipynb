{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from metrics.metrics import det_precision_at_one, precision_at_one\n",
    "from loss_functions.loss_functions import full_pairwise_softmax\n",
    "from train_utils.container import ModelContainer\n",
    "from application.model import ApplicationModel\n",
    "from batch_generator.dir import DirIterator\n",
    "from text_sparsifiers.sparsifiers import make_sparsifiers\n",
    "from application.numpy_storage import NumpyStorage\n",
    "from application.applier import Applier\n",
    "from application.context_preparer import ContextPreparer\n",
    "from dataset.reddit import prepare_reddit, convert\n",
    "from text_sparsifiers.tokenizers import sequential_tokenizer, filling, filling_words, \\\n",
    "    make_filling_character_ngram, words\n",
    "from batch_generator.flavors import PLAIN_REPLY, PLAIN_TRAIN, PLAIN_TEST\n",
    "from model.baseline import Baseline\n",
    "from trainer.callbacks.reduce_lr_on_plateu import ReduceLROnPlateu\n",
    "from trainer.callbacks.save_best import SaveBest\n",
    "from batch_generator.batch_generator import func_batch_generator, BatchGenerator\n",
    "from trainer.tensorboard_trainer import TensorBoardTrainer\n",
    "from trainer.tester import Tester\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "CONTEXT_LEN = 3\n",
    "\n",
    "CONFIG_DIR = \"/data/reddit/models/baseline/\"\n",
    "TRAIN_DATA = \"/data/reddit/f_4_train_filtered/\"\n",
    "VAL_DATA = \"/data/reddit/f_4_val_filtered/\"\n",
    "TEST_DATA = \"/data/reddit/f_4_test_filtered\"\n",
    "\n",
    "REDDIT_TF_WEIGHTS_FNAME = \"reddit_tf_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterator = DirIterator.from_data_folder(TRAIN_DATA)\n",
    "val_iterator = DirIterator.from_data_folder(VAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = ModelContainer(CONFIG_DIR, ckpt=REDDIT_TF_WEIGHTS_FNAME, dill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################\n",
    "Тут генерятся спарсифаеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filling_character_ngram = make_filling_character_ngram()\n",
    "keys = ['context', 'reply']\n",
    "vocabulary_size = {key: 2 for key in keys}\n",
    "modes = {key: 'occurrences' for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparsifiers = make_sparsifiers(train_iterator, filling_character_ngram, \n",
    "                                     vocabulary_size=vocabulary_size, modes=modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc.write('sparsifiers', sparsifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparsifiers = mc.read('sparsifiers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'reply': {'vocabulary_size': sparsifiers['reply'].vocabulary_size,\n",
    "                    'embedding_size': 100,\n",
    "                    'hiddens': [100, 100]},\n",
    "         'context': {'vocabulary_size': sparsifiers['context'].vocabulary_size,\n",
    "                    'embedding_size': 100,\n",
    "                    'hiddens': [200, 100, 100]},\n",
    "         'batch_size': BATCH_SIZE,\n",
    "         'context_len': CONTEXT_LEN}\n",
    "\n",
    "mc.write('model_params', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# почистить все логи: трейна, валидации, теста\n",
    "\n",
    "mc.clear_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    model_box = Baseline(mc).make_model()\n",
    "    \n",
    "    loss = model_box.make_loss(full_pairwise_softmax)\n",
    "    dpao = model_box.make_loss(det_precision_at_one)\n",
    "    \n",
    "    learning_rate = tf.Variable(0.001, trainable=False)\n",
    "    rlr = ReduceLROnPlateu(learning_rate, factor=0.3, patience=100, min_lr=0.000001)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    \n",
    "    sb = SaveBest(10)\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, val_gen = [func_batch_generator(iterator, mc, PLAIN_TRAIN) \n",
    "                      for iterator in [train_iterator, val_iterator]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_trainer = TensorBoardTrainer(mc, train_step, ('loss', loss), [('dpao', dpao)], model_box, \n",
    "                                 train_gen, val_gen, [rlr, sb], val_steps=50, epoch_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tensorboard --logdir /data/reddit/models/baseline```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lol_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_trainer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Здесь запуск на тесте + эмбеддинги в tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = Tester(mc, TEST_DATA, PLAIN_TEST, model_box, [dpao])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83943826], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.get_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для tSNE 5к точек -- самое оно, больше только если вы на PCA хотите посмотреть или ещё че."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester.write_embeddings(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tensorboard --logdir /data/reddit_f_60_utils_lstm_2/testing```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Здесь поболтать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /data/reddit/models/baseline/reddit_tf_weights_-1\n"
     ]
    }
   ],
   "source": [
    "tm = ApplicationModel(mc, model=Baseline(mc), flavor=PLAIN_REPLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_storage = NumpyStorage()\n",
    "context_preparer = ContextPreparer(convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################\n",
    "\n",
    "Это запустить, если хотите сгенерировать вектора реплаев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file_limit -- количество файлов, из которых брать реплаи\n",
    "\n",
    "iterator = DirIterator.from_data_folder(TRAIN_DATA, file_limit=50) \n",
    "gen = BatchGenerator(iterator, mc, PLAIN_REPLY, infinite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1212it [00:13, 88.18it/s]\n"
     ]
    }
   ],
   "source": [
    "ap = Applier.from_gen(tm, vector_storage, context_preparer, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap.to_pickle(mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap = Applier.from_pickle(tm, vector_storage, context_preparer, mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dialogue = [\"Mama\",\n",
    "            \"Here I am\"]\n",
    "message = None\n",
    "while message != 'exit':\n",
    "    message = input()\n",
    "    dialogue.append(message)\n",
    "    reply = ap.reply(dialogue[-3:])\n",
    "    print(reply)\n",
    "    dialogue.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
